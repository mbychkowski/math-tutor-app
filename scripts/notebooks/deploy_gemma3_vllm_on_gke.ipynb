{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "7d9bbf86da5e"
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99c1c3fc2ca5"
   },
   "source": [
    "# Gemma deployment to GKE using vLLM on GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3de7470326a2"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates downloading and deploying Gemma, open models from Google DeepMind. In this guide we specifically use L4 GPUs but this guide should also work for A100(40 GB), A100(80 GB), H100(80 GB) GPUs.\n",
    "\n",
    "\n",
    "### Objective\n",
    "\n",
    "Deploy and run inference for serving Gemma with vLLM on GPUs.\n",
    "\n",
    "### GPUs\n",
    "\n",
    "GPUs let you accelerate specific workloads running on your nodes such as machine learning and data processing. GKE provides a range of machine type options for node configuration, including machine types with NVIDIA H100, L4, and A100 GPUs.\n",
    "\n",
    "Before you use GPUs in GKE, we recommend that you complete the following learning path:\n",
    "\n",
    "Learn about [current GPU version availability](https://cloud.google.com/compute/docs/gpus)\n",
    "\n",
    "Learn about [GPUs in GKE](https://cloud.google.com/kubernetes-engine/docs/concepts/gpus)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXKO7CLz3U8x"
   },
   "source": [
    "### Pre requisites\n",
    "- Install Google Cloud CLI\n",
    "https://cloud.google.com/sdk/docs/install-sdk  (note: pre-installed in Cloud Shell)\n",
    "- Install kubectl (note: pre-installed in Cloud Shell)\n",
    "- Create a .env file with the following values\n",
    "\n",
    "\n",
    "```\n",
    "PROJECT_ID\n",
    "REGION \n",
    "HF_TOKEN # Optional if you want to download model from Hugging Face\n",
    "KSA_NAME \n",
    "PROJECT_NUMBER\n",
    "CLUSTER_NAME \n",
    "\n",
    "# Assuming the model is saved at : gs://{MODEL_BUCKET}/{MODEL_NAME}/{MODEL_VERSION}\n",
    "MODEL_BUCKET \n",
    "MODEL_NAME\n",
    "MODEL_VERSION\n",
    "IMAGE_NAME\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "264c07757582"
   },
   "source": [
    "## Create a GKE cluster and node pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8467,
     "status": "ok",
     "timestamp": 1754332525066,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "jGogmQvl2wZ-",
    "outputId": "88ac1f97-943b-4d70-e89c-ac46823636c3"
   },
   "outputs": [],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSm5s9I_5N40"
   },
   "source": [
    "**Restart the runtime session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1282,
     "status": "ok",
     "timestamp": 1754332535008,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "2Q_hqg0X2svT"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()  # This loads the variables from .env into the environment\n",
    "\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "REGION = os.getenv(\"REGION\")\n",
    "#HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "PROJECT_NUMBER = os.getenv(\"PROJECT_NUMBER\")\n",
    "KSA_NAME = os.getenv(\"KSA_NAME\")\n",
    "CLUSTER_NAME = os.getenv(\"CLUSTER_NAME\")\n",
    "\n",
    "# Assuming the model is saved at : gs://{MODEL_BUCKET}/{MODEL_NAME}/{MODEL_VERSION}\n",
    "MODEL_BUCKET = os.getenv(\"MODEL_BUCKET\")\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\")\n",
    "MODEL_VERSION = os.getenv(\"MODEL_VERSION\")\n",
    "IMAGE_NAME = os.getenv(\"IMAGE_NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "# The HuggingFace token used to download models.\n",
    "\n",
    "# assert HF_TOKEN, \"Set Hugging Face access token in `HF_TOKEN`.\"\n",
    "\n",
    "# Set up gcloud.\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "!gcloud services enable container.googleapis.com\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating cluster: crashai\n",
      "\u001b[1;33mWARNING:\u001b[0m Accessing a Kubernetes Engine cluster requires the kubernetes commandline\n",
      "client [kubectl]. To install, run\n",
      "  $ gcloud components install kubectl\n",
      "\n",
      "Note: The Kubelet readonly port (10255) is now deprecated. Please update your workloads to use the recommended alternatives. See https://cloud.google.com/kubernetes-engine/docs/how-to/disable-kubelet-readonly-port for ways to check usage and for migration instructions.\n",
      "Note: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s).\n",
      "Creating cluster crashai in us-central1... Cluster is being health-checked (Kub\n",
      "ernetes Control Plane is healthy)...done.                                      \n",
      "Created [https://container.googleapis.com/v1/projects/prj-kokiri-dev/zones/us-central1/clusters/crashai].\n",
      "To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1/crashai?project=prj-kokiri-dev\n",
      "\u001b[1;31mCRITICAL: ACTION REQUIRED: gke-gcloud-auth-plugin, which is needed for continued use of kubectl, was not found or is not executable. Install gke-gcloud-auth-plugin for use with kubectl by following https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-access-for-kubectl#install_plugin\u001b[0m\n",
      "kubeconfig entry generated for crashai.\n",
      "NAME     LOCATION     MASTER_VERSION      MASTER_IP      MACHINE_TYPE  NODE_VERSION        NUM_NODES  STATUS   STACK_TYPE\n",
      "crashai  us-central1  1.33.2-gke.1240000  34.122.206.87  e2-medium     1.33.2-gke.1240000  12         RUNNING  IPV4\n",
      "Note: Machines with GPUs have certain limitations which may affect your workflow. Learn more at https://cloud.google.com/kubernetes-engine/docs/how-to/gpus\n",
      "Note: Starting in GKE 1.30.1-gke.115600, if you don't specify a driver version, GKE installs the default GPU driver for your node's GKE version.\n",
      "Creating node pool gpupool...done.                                             \n",
      "Created [https://container.googleapis.com/v1/projects/prj-kokiri-dev/zones/us-central1/clusters/crashai/nodePools/gpupool].\n",
      "NAME     MACHINE_TYPE    DISK_SIZE_GB  NODE_VERSION\n",
      "gpupool  g2-standard-24  100           1.33.2-gke.1240000\n",
      "\u001b[1;33mWARNING:\u001b[0m Accessing a Kubernetes Engine cluster requires the kubernetes commandline\n",
      "client [kubectl]. To install, run\n",
      "  $ gcloud components install kubectl\n",
      "\n",
      "Fetching cluster endpoint and auth data.\n",
      "\u001b[1;31mCRITICAL: ACTION REQUIRED: gke-gcloud-auth-plugin, which is needed for continued use of kubectl, was not found or is not executable. Install gke-gcloud-auth-plugin for use with kubectl by following https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-access-for-kubectl#install_plugin\u001b[0m\n",
      "kubeconfig entry generated for crashai.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "# # Create a unique cluster name to avoid conflicts.\n",
    "# now = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "# CLUSTER_NAME=f\"gke-gemma-cluster-test-{now}\"\n",
    "\n",
    "print(f\"Creating cluster: {CLUSTER_NAME}\")\n",
    "\n",
    "! gcloud container clusters create {CLUSTER_NAME} \\\n",
    "    --project={PROJECT_ID} \\\n",
    "    --region={REGION} \\\n",
    "    --subnetwork=\"default\" \\\n",
    "    --workload-pool={PROJECT_ID}.svc.id.goog \\\n",
    "    --release-channel=rapid \\\n",
    "    --num-nodes=4 \\\n",
    "    --enable-shielded-nodes \\\n",
    "    --shielded-secure-boot\\\n",
    "    --shielded-integrity-monitoring \\\n",
    "    --addons=GcsFuseCsiDriver\n",
    "\n",
    "! gcloud container node-pools create gpupool \\\n",
    "    --accelerator=type=nvidia-l4,count=2,gpu-driver-version=latest \\\n",
    "    --project={PROJECT_ID} \\\n",
    "    --location={REGION} \\\n",
    "    --node-locations={REGION}-a \\\n",
    "    --cluster={CLUSTER_NAME} \\\n",
    "    --machine-type=g2-standard-24 \\\n",
    "    --num-nodes=1 \\\n",
    "    --shielded-secure-boot \\\n",
    "    --shielded-integrity-monitoring\n",
    "\n",
    "! gcloud container clusters get-credentials {CLUSTER_NAME} --location {REGION}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for crashai.\n"
     ]
    }
   ],
   "source": [
    "! gcloud container clusters get-credentials {CLUSTER_NAME} --location {REGION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n06Ni3y9zGzC"
   },
   "source": [
    "### (Optional, only needed if load model from HF) Create a Kubernetes secret for Hugging Face credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1338,
     "status": "ok",
     "timestamp": 1754332580740,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "Q1nW_fsPzEYE",
    "outputId": "c16b2633-62a5-4906-ae5e-2ade12852c36"
   },
   "outputs": [],
   "source": [
    "# Create Kubernetes secret for Hugging Face credentials\n",
    "#! kubectl create secret generic hf-secret \\\n",
    "#    --from-literal=hf_api_token={HF_TOKEN} \\\n",
    "#    --dry-run=client -o yaml > hf-secret.yaml\n",
    "#\n",
    "#! kubectl apply -f hf-secret.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceaccount/crashai created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create serviceaccount {KSA_NAME}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated IAM policy for project [prj-kokiri-dev].\n",
      "bindings:\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-alloydb.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.user\n",
      "- members:\n",
      "  - group:cloud-developers@mbychkowski.altostrat.com\n",
      "  role: roles/alloydb.databaseUser\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-alloydb.iam.gserviceaccount.com\n",
      "  role: roles/alloydb.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-servicemesh.iam.gserviceaccount.com\n",
      "  role: roles/anthosservicemesh.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-test@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/artifactregistry.admin\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/artifactregistry.reader\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  role: roles/artifactregistry.repoAdmin\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:service-933718959305@gcp-sa-artifactregistry.iam.gserviceaccount.com\n",
      "  role: roles/artifactregistry.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/artifactregistry.writer\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.builds.builder\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.builds.editor\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.connectionAdmin\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-cloudbuild.iam.gserviceaccount.com\n",
      "  role: roles/cloudbuild.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/clouddeploy.developer\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/clouddeploy.jobRunner\n",
      "- members:\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/clouddeploy.operator\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/clouddeploy.releaser\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-clouddeploy.iam.gserviceaccount.com\n",
      "  role: roles/clouddeploy.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/cloudtrace.agent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@cloudcomposer-accounts.iam.gserviceaccount.com\n",
      "  role: roles/composer.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/compute.admin\n",
      "- members:\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/compute.networkAdmin\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@compute-system.iam.gserviceaccount.com\n",
      "  role: roles/compute.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/compute.viewer\n",
      "- members:\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/container.admin\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/container.clusterAdmin\n",
      "- members:\n",
      "  - principal://iam.googleapis.com/projects/933718959305/locations/global/workloadIdentityPools/prj-kokiri-dev.svc.id.goog/subject/ns/default/sa/crashai\n",
      "  role: roles/container.clusterViewer\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-gkenode.iam.gserviceaccount.com\n",
      "  role: roles/container.defaultNodeServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-deploy-exec@prj-hyrule-hub.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/container.developer\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/container.nodeServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@container-engine-robot.iam.gserviceaccount.com\n",
      "  role: roles/container.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@containerregistry.iam.gserviceaccount.com\n",
      "  role: roles/containerregistry.ServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@dataflow-service-producer-prod.iam.gserviceaccount.com\n",
      "  role: roles/dataflow.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-dataplex.iam.gserviceaccount.com\n",
      "  role: roles/dataplex.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@dataproc-accounts.iam.gserviceaccount.com\n",
      "  role: roles/dataproc.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-devconnect.iam.gserviceaccount.com\n",
      "  role: roles/developerconnect.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:933718959305@cloudservices.gserviceaccount.com\n",
      "  - user:giovanejr@mbychkowski.altostrat.com\n",
      "  role: roles/editor\n",
      "- members:\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/eventarc.developer\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/eventarc.eventReceiver\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-eventarc.iam.gserviceaccount.com\n",
      "  role: roles/eventarc.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:firebase-service-account@firebase-sa-management.iam.gserviceaccount.com\n",
      "  - serviceAccount:service-933718959305@gcp-sa-firebase.iam.gserviceaccount.com\n",
      "  role: roles/firebase.managementServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:firebase-adminsdk-5zllo@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/firebase.sdkAdminServiceAgent\n",
      "- members:\n",
      "  - serviceAccount:firebase-adminsdk-5zllo@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/firebaseauth.admin\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-firebasevertexai.iam.gserviceaccount.com\n",
      "  role: roles/firebaseml.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@firebase-rules.iam.gserviceaccount.com\n",
      "  role: roles/firebaserules.system\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-firestore.iam.gserviceaccount.com\n",
      "  role: roles/firestore.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-gkehub.iam.gserviceaccount.com\n",
      "  role: roles/gkehub.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/iam.serviceAccountAdmin\n",
      "- members:\n",
      "  - serviceAccount:firebase-adminsdk-5zllo@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:service-933718959305@gcp-sa-pubsub.iam.gserviceaccount.com\n",
      "  role: roles/iam.serviceAccountTokenCreator\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-deploy-exec@prj-hyrule-hub.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/iam.serviceAccountUser\n",
      "- members:\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/logging.configWriter\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/logging.logWriter\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-meshcontrolplane.iam.gserviceaccount.com\n",
      "  role: roles/meshcontrolplane.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-meshdataplane.iam.gserviceaccount.com\n",
      "  role: roles/meshdataplane.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/monitoring.metricWriter\n",
      "- members:\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/monitoring.viewer\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-mcmetering.iam.gserviceaccount.com\n",
      "  role: roles/multiclustermetering.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-networkactions.iam.gserviceaccount.com\n",
      "  role: roles/networkactions.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-networkconnectivity.iam.gserviceaccount.com\n",
      "  role: roles/networkconnectivity.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-notebooks.iam.gserviceaccount.com\n",
      "  role: roles/notebooks.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-osconfig.iam.gserviceaccount.com\n",
      "  role: roles/osconfig.serviceAgent\n",
      "- members:\n",
      "  - user:admin@mbychkowski.altostrat.com\n",
      "  role: roles/owner\n",
      "- members:\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/pubsub.editor\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gs-project-accounts.iam.gserviceaccount.com\n",
      "  role: roles/pubsub.publisher\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-pubsub.iam.gserviceaccount.com\n",
      "  role: roles/pubsub.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/pubsub.subscriber\n",
      "- members:\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/resourcemanager.projectIamAdmin\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:sa-deploy-exec@prj-hyrule-hub.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/run.developer\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/run.invoker\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@serverless-robot-prod.iam.gserviceaccount.com\n",
      "  role: roles/run.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-runapps.iam.gserviceaccount.com\n",
      "  role: roles/runapps.serviceAgent\n",
      "- condition:\n",
      "    expression: request.time < timestamp(\"2024-02-21T22:54:38.363Z\")\n",
      "    title: cloudbuild-connection-setup\n",
      "  members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-cloudbuild.iam.gserviceaccount.com\n",
      "  role: roles/secretmanager.admin\n",
      "- condition:\n",
      "    expression: request.time < timestamp(\"2024-06-18T18:55:54.837Z\")\n",
      "    title: developer-connect-connection-setup\n",
      "  members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-devconnect.iam.gserviceaccount.com\n",
      "  role: roles/secretmanager.admin\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-dep.iam.gserviceaccount.com\n",
      "  role: roles/serviceextensions.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@service-networking.iam.gserviceaccount.com\n",
      "  role: roles/servicenetworking.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  role: roles/source.reader\n",
      "- members:\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/stackdriver.resourceMetadata.writer\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/storage.admin\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:sa-deploy-exec@prj-hyrule-hub.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-gh-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/storage.objectAdmin\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  role: roles/storage.objectCreator\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:gsa-wi-encoder@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  - serviceAccount:sa-naps-gke-cluster@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/storage.objectUser\n",
      "- members:\n",
      "  - serviceAccount:933718959305@cloudbuild.gserviceaccount.com\n",
      "  role: roles/storage.objectViewer\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-vpcaccess.iam.gserviceaccount.com\n",
      "  role: roles/vpcaccess.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:sa-github-actions@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/workflows.editor\n",
      "- members:\n",
      "  - serviceAccount:933718959305-compute@developer.gserviceaccount.com\n",
      "  - serviceAccount:eventarc-workflows-sa@prj-kokiri-dev.iam.gserviceaccount.com\n",
      "  role: roles/workflows.invoker\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-workflows.iam.gserviceaccount.com\n",
      "  role: roles/workflows.serviceAgent\n",
      "- members:\n",
      "  - serviceAccount:service-933718959305@gcp-sa-workstations.iam.gserviceaccount.com\n",
      "  role: roles/workstations.serviceAgent\n",
      "etag: BwY74vSYbjk=\n",
      "version: 3\n"
     ]
    }
   ],
   "source": [
    "! gcloud projects add-iam-policy-binding projects/{PROJECT_ID} \\\n",
    "    --role=roles/container.clusterViewer \\\n",
    "    --member=principal://iam.googleapis.com/projects/{PROJECT_NUMBER}/locations/global/workloadIdentityPools/{PROJECT_ID}.svc.id.goog/subject/ns/default/sa/{KSA_NAME} \\\n",
    "    --condition=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional)Copy Gemma3 model data to your bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source model: gs://<source_bucket>/<model_name>/<model_version>\n",
    "## Assuming the model will be saved at : gs://{MODEL_BUCKET}/{MODEL_NAME}/{MODEL_VERSION}\n",
    "\n",
    "#! gcloud storage cp --recursive gs://the-fine-tuners/gemma3-1b-vertex gs://{MODEL_BUCKET}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bindings:\n",
      "- members:\n",
      "  - projectEditor:prj-kokiri-dev\n",
      "  - projectOwner:prj-kokiri-dev\n",
      "  role: roles/storage.legacyBucketOwner\n",
      "- members:\n",
      "  - projectViewer:prj-kokiri-dev\n",
      "  role: roles/storage.legacyBucketReader\n",
      "- members:\n",
      "  - projectEditor:prj-kokiri-dev\n",
      "  - projectOwner:prj-kokiri-dev\n",
      "  role: roles/storage.legacyObjectOwner\n",
      "- members:\n",
      "  - projectViewer:prj-kokiri-dev\n",
      "  role: roles/storage.legacyObjectReader\n",
      "- members:\n",
      "  - principal://iam.googleapis.com/projects/933718959305/locations/global/workloadIdentityPools/prj-kokiri-dev.svc.id.goog/subject/ns/default/sa/crashai\n",
      "  role: roles/storage.objectViewer\n",
      "etag: CAM=\n",
      "kind: storage#policy\n",
      "resourceId: projects/_/buckets/prj-kokiri-dev-the-fine-tuners\n",
      "version: 1\n"
     ]
    }
   ],
   "source": [
    "! gcloud storage buckets add-iam-policy-binding gs://{MODEL_BUCKET} \\\n",
    "    --role=roles/storage.objectViewer \\\n",
    "    --member=principal://iam.googleapis.com/projects/{PROJECT_NUMBER}/locations/global/workloadIdentityPools/{PROJECT_ID}.svc.id.goog/subject/ns/default/sa/{KSA_NAME} \\\n",
    "    --condition=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V_MODEL_BUCKET = MODEL_BUCKET\n",
    "V_MODEL_NAME =MODEL_NAME\n",
    "V_MODEL_VERSION=MODEL_VERSION\n",
    "V_IMAGE_NAME=IMAGE_NAME\n",
    "V_KSA=KSA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6psJZY_zUDgj",
    "outputId": "1c206c0e-fac0-4ba8-c8ca-08af582830fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/vllm-gemma3-deployment created\n",
      "service/llm-service unchanged\n",
      "Waiting for container to be created...\n",
      "\n",
      "NAME                                     READY   STATUS    RESTARTS   AGE\n",
      "vllm-gemma3-deployment-fb9f96bd5-2h7m9   1/2     Running   0          3m35s\n",
      "\n",
      "Downloading artifacts...\n",
      "Server is up and running.\n"
     ]
    }
   ],
   "source": [
    "# @title Deploy Gemma3\n",
    "\n",
    "# @markdown This section deploys Gemma.\n",
    "\n",
    "# @markdown Select one of the following model version and size options:\n",
    "\n",
    "# The size of the model to launch\n",
    "\n",
    "\n",
    "K8S_YAML_GCS=f\"\"\"apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: vllm-gemma3-deployment\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: gemma-server\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: gemma-server\n",
    "      annotations:\n",
    "        gke-gcsfuse/volumes: \"true\"\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: inference-server\n",
    "        command: [\"python3\", \"-m\", \"vllm.entrypoints.openai.api_server\"]\n",
    "        args:\n",
    "        - --model=$(MODEL)\n",
    "        - --tensor-parallel-size=1\n",
    "        - --host=0.0.0.0\n",
    "        - --port=8000\n",
    "        env:\n",
    "        - name: MODEL\n",
    "          value: /gcs/{V_MODEL_NAME}/{V_MODEL_VERSION}\n",
    "        - name: VLLM_ATTENTION_BACKEND\n",
    "          value: FLASHINFER\n",
    "        image: {V_IMAGE_NAME}\n",
    "        readinessProbe:\n",
    "          failureThreshold: 3\n",
    "          httpGet:\n",
    "            path: /health\n",
    "            port: 8000\n",
    "            scheme: HTTP\n",
    "          initialDelaySeconds: 240\n",
    "          periodSeconds: 5\n",
    "          successThreshold: 1\n",
    "          timeoutSeconds: 1\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: \"2\"\n",
    "            memory: \"25Gi\"\n",
    "            nvidia.com/gpu: \"1\"\n",
    "          limits:\n",
    "            cpu: \"2\"\n",
    "            memory: \"25Gi\"\n",
    "            nvidia.com/gpu: \"1\"\n",
    "        volumeMounts:\n",
    "        - mountPath: /dev/shm\n",
    "          name: dshm\n",
    "        - name: gcs-fuse-csi-ephemeral\n",
    "          mountPath: /gcs\n",
    "          readOnly: true\n",
    "      nodeSelector:\n",
    "        cloud.google.com/gke-accelerator: nvidia-l4\n",
    "        cloud.google.com/gke-gpu-driver-version: latest\n",
    "      serviceAccountName: {V_KSA}\n",
    "      tolerations:\n",
    "      - key: \"nvidia.com/gpu\"\n",
    "        operator: \"Exists\"\n",
    "        effect: \"NoSchedule\"\n",
    "      - key: \"on-demand\"\n",
    "        value: \"true\"\n",
    "        operator: \"Equal\"\n",
    "        effect: \"NoSchedule\"\n",
    "      volumes:\n",
    "      - name: dshm\n",
    "        emptyDir:\n",
    "            medium: Memory\n",
    "      - name: gcs-fuse-csi-ephemeral\n",
    "        csi:\n",
    "          driver: gcsfuse.csi.storage.gke.io\n",
    "          volumeAttributes:\n",
    "            bucketName: {V_MODEL_BUCKET}\n",
    "            mountOptions: \"implicit-dirs,file-cache:enable-parallel-downloads:true,file-cache:max-parallel-downloads:-1\"\n",
    "            fileCacheCapacity: \"20Gi\"\n",
    "            fileCacheForRangeRead: \"true\"\n",
    "            metadataStatCacheCapacity: \"-1\"\n",
    "            metadataTypeCacheCapacity: \"-1\"\n",
    "            metadataCacheTTLSeconds: \"-1\"\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: llm-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: gemma-server\n",
    "  type: ClusterIP\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 8000\n",
    "      targetPort: 8000\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "K8S_YAML_HF=\"\"\"apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: vllm-gemma-deployment\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: gemma-server\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: gemma-server\n",
    "        ai.gke.io/model: gemma-3-1b-it\n",
    "        ai.gke.io/inference-server: vllm\n",
    "        examples.ai.gke.io/source: user-guide\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: inference-server\n",
    "        image: us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20250312_0916_RC01\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: \"4\"\n",
    "            memory: \"30Gi\"\n",
    "            ephemeral-storage: \"30Gi\"\n",
    "            nvidia.com/gpu: \"1\"\n",
    "          limits:\n",
    "            cpu: \"4\"\n",
    "            memory: \"30Gi\"\n",
    "            ephemeral-storage: \"30Gi\"\n",
    "            nvidia.com/gpu: \"1\"\n",
    "        command: [\"python3\", \"-m\", \"vllm.entrypoints.openai.api_server\"]\n",
    "        args:\n",
    "        - --model=$(MODEL_ID)\n",
    "        - --tensor-parallel-size=1\n",
    "        - --host=0.0.0.0\n",
    "        - --port=8000\n",
    "        env:\n",
    "        - name: MODEL_ID\n",
    "          value: google/gemma-3-1b-it\n",
    "        - name: HUGGING_FACE_HUB_TOKEN\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: hf-secret\n",
    "              key: hf_api_token\n",
    "        volumeMounts:\n",
    "        - mountPath: /dev/shm\n",
    "          name: dshm\n",
    "      volumes:\n",
    "      - name: dshm\n",
    "        emptyDir:\n",
    "            medium: Memory\n",
    "      nodeSelector:\n",
    "        cloud.google.com/gke-accelerator: nvidia-l4\n",
    "        cloud.google.com/gke-gpu-driver-version: latest\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: llm-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: gemma-server\n",
    "  type: ClusterIP\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 8000\n",
    "      targetPort: 8000\n",
    "\"\"\"\n",
    "\n",
    "with open(\"vllm-3-1b-it-ft.yaml\", \"w\") as f:\n",
    "    f.write(K8S_YAML_GCS)\n",
    "\n",
    "! kubectl apply -f vllm-3-1b-it-ft.yaml\n",
    "\n",
    "# Wait for container to be created.\n",
    "import time\n",
    "\n",
    "print(\"Waiting for container to be created...\\n\")\n",
    "while True:\n",
    "    shell_output = ! kubectl get pod\n",
    "    container_status = \"\\n\".join(shell_output)\n",
    "    if \"1/1\" in container_status or \"Running\" in container_status:\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "print(container_status)\n",
    "\n",
    "# Wait for downloading artifacts.\n",
    "print(\"\\nDownloading artifacts...\")\n",
    "while True:\n",
    "    shell_output = ! kubectl logs -l app=gemma-server\n",
    "    logs = \"\\n\".join(shell_output)\n",
    "    if \"Application startup complete\" in logs:\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "print(\"Server is up and running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLG4OLSawOJ3"
   },
   "source": [
    "### Follow this to test the model\n",
    "Connect to the cluster\n",
    "\n",
    "```\n",
    "gcloud container clusters get-credentials {CLUSTER_NAME} --location {REGION}\n",
    "```\n",
    "\n",
    "Forward the port\n",
    "\n",
    "```\n",
    "kubectl port-forward service/llm-service 8000:8000\n",
    "```\n",
    "\n",
    "Open another terminal:\n",
    "```\n",
    "curl http://127.0.0.1:8000/v1/chat/completions \\\n",
    "-X POST \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "    \"model\": \"<your model name>\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"what is the capital of USA?\"\n",
    "        }\n",
    "    ]\n",
    "}'\n",
    "```\n",
    "\n",
    "\n",
    "reference: https://cloud.google.com/kubernetes-engine/docs/tutorials/serve-gemma-gpu-vllm#serve-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbRmgoOZF6es"
   },
   "source": [
    "## Clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "911406c1561e"
   },
   "outputs": [],
   "source": [
    "# @markdown  Delete the experiment models and endpoints to recycle the resources\n",
    "# @markdown  and avoid unnecessary continouous charges that may incur.\n",
    "\n",
    "! kubectl delete deployments vllm-gemma3-deployment\n",
    "! kubectl delete services llm-service\n",
    "! kubectl delete secrets hf-secret\n",
    "\n",
    "DELETE_CLUSTER = False # @param {type: \"boolean\"}\n",
    "\n",
    "if DELETE_CLUSTER:\n",
    "  ! gcloud container clusters delete {CLUSTER_NAME} \\\n",
    "    --region={REGION} \\\n",
    "    --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "deploy_gemma3_vllm_on_gke.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
